{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Customer Queries \n",
    "\n",
    "Using simple machine learning techniques to solve actual business problems\n",
    "\n",
    "----\n",
    "## 1. Problem statement\n",
    "Every company has customers and customers have complaints. <br>\n",
    "For this project, we have a dataset that contains different queries from customers. <br>\n",
    "Now in this case, each query we receive from the customer falls into one of two categories -\n",
    "* A generic query that can be dealt with automatically (category 0)\n",
    "* A complex query that requires human intervention (category 1)\n",
    "\n",
    "---\n",
    "## 2. Approach to solution:\n",
    "* Here our objective is to build a model that can <i>predict</i> whether a query requires immediate attention (1) or not (0)\n",
    "\n",
    "\n",
    "#### <b>2.1 Preparing the dataset</b>\n",
    "* We are using publicly available dataset from an E-Learning website \n",
    "* Let us first import necessary libs & import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Query</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be or do</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comparatives and superlatives</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how to teach overcoming obstacles concept with...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Present perfect simple or continuous</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Input Query  Category\n",
       "0                                           be or do         0\n",
       "1                      comparatives and superlatives         0\n",
       "2  how to teach overcoming obstacles concept with...         1\n",
       "3               Present perfect simple or continuous         0\n",
       "4                                                  -         0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "data=pd.read_csv('query_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 - <i>Low level query </i><br>\n",
    "1 - <i>Urgent query (needs immediate attention) </i>\n",
    "\n",
    "* Shuffling the dataset to curb any unnecessary biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1084, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(frac = 1, random_state=11)\n",
    "data.head()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b> 2.2 Vectorization of words</b>\n",
    "Algorithms cannot ingest raw text, so we will have to convert it into numbers. <br>\n",
    "There are multiple methods to achieve this.\n",
    "\n",
    "* <b> Counting Word frequency </b> (Bag of words) -\n",
    "<br> In this approach, we use the tokenized words for each observation and find out the frequency of each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "count_example = (count_vec.fit_transform(data[\"Input Query\"].values.astype('U'))).toarray()\n",
    "count_example = pd.DataFrame(count_example)\n",
    "vocab_list = list(count_vec.get_feature_names())\n",
    "\n",
    "i=0\n",
    "for i in range(len(count_example.columns)):\n",
    "    count_example.rename(columns={i: vocab_list[i]}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1084, 1182)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_example.shape\n",
    "#count_example.to_csv(\"countexample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, that this method is not effiecent since sparse matrix between document and token generated 1084 x 1182 cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b> Hashing Vectorization </b> - <br>\n",
    "In this approach, the algorithm looks at how words tend to cluster in different contexts & find relations between them based on how they were used in the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.027778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.027778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8         9     ...   1014  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 -0.027778  ...    0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  ...    0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  ...    0.0   \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  ...    0.0   \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  ...    0.0   \n",
       "\n",
       "   1015  1016  1017  1018      1019  1020  1021  1022  1023  \n",
       "0   0.0   0.0   0.0   0.0 -0.027778   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 1024 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = HashingVectorizer(n_features = 2**10, norm=\"l1\")\n",
    "vec_counts = (vec.fit_transform(data[\"Input Query\"].values.astype('U'))).toarray()\n",
    "train = pd.DataFrame(vec_counts)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1084, 1024)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main advantage of using this method is even if we increase the observations to 100k, we can still limit the featuer count to 1024. <br>\n",
    "\n",
    "#### <b>2.3 Dimensionality reduction using PCA </b>\n",
    "We still have a lot of features. As you might notice, there are lot of zeroes in the dataset which seems unnecessary & inefficient.\n",
    "* Principal component analysis is a statistical procedure to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components\n",
    "* The \"0.99\" means that we want the compression to retain 99% of the original data´s significance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # cols before PCA: 1024 \n",
      " # cols after PCA: 371\n"
     ]
    }
   ],
   "source": [
    "train_rows, train_cols = train.shape\n",
    "pca_compressor = PCA(0.99)\n",
    "comp_train = pd.DataFrame(pca_compressor.fit_transform(train))\n",
    "comp_rows, comp_cols = comp_train.shape\n",
    "print(\" # cols before PCA:\",train_cols,\"\\n\",\"# cols after PCA:\" ,comp_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We´ve reduced the size of the dataset by 65% and all losing 1% significance of the original data. As you can see, we no longer have sparse zero columns, everything has been compressed as tightly as possible in order to have as few columns as possible. This now makes our data far more scalable when adding examples to it in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b> 2.4 Training & Evaluating the model </b>\n",
    "We already have a labelled dataset. Now our we have to train our model to learn the relation between each input text and it´s label category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ans = data['Category']\n",
    "train_ans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b> Precision, Recall & F1 score: </b> <br>\n",
    "Before deploying the solution, we must always take into the account the business side of it. <br>\n",
    "For eg, in this scenario if \n",
    "    - the model classifies 0 (non urgent) as 1 (urgent) then it does not cause major problem\n",
    "    - but if the model classifies 1 (urgent) as 0 (non urgent) then it will lead to customer dissatisfaction <br>\n",
    "\n",
    "So in this case <i>Recall </i> is an important evaluation metric compared to <i>Precision</i> <br>\n",
    "We´ll assign a heavier weight to the \"1\" category because we want to be as certain as possible to always detect that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjusting the weights\n",
    "class_weights = {0:0.13, 1:0.87}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b> Using linear SVC </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=7, class_weight={0: 0.13, 1: 0.87}, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=1e-07,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting SVC\n",
    "svc_model = LinearSVC(C=7, dual = True, loss=\"squared_hinge\", penalty = \"l2\", tol=1e-7, class_weight=class_weights)\n",
    "svc_model.fit(comp_train, train_ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fit our learning algorithm, lets check the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model True Pos -  172 False Pos - 341 True Neg -  551 False neg -  20\n",
      "Model's Accuracy: 66.69741697416974 %\n",
      "Model´s Precision: 33.528265107212476 %\n",
      "Model´s Recall: 89.58333333333334 %\n",
      "Model´s F1: 48.79432624113475 %\n"
     ]
    }
   ],
   "source": [
    "TP=0\n",
    "TN=0\n",
    "FP=0\n",
    "FN=0\n",
    "\n",
    "for i in range(len(train)):\n",
    "    if svc_model.predict(comp_train.iloc[[i,]])==1 and train_ans.iloc[i]==1:\n",
    "        TP = TP + 1\n",
    "    if svc_model.predict(comp_train.iloc[[i,]])==1 and train_ans.iloc[i]==0:\n",
    "        FP = FP + 1\n",
    "    if svc_model.predict(comp_train.iloc[[i,]])==0 and train_ans.iloc[i]==0:\n",
    "        TN = TN + 1\n",
    "    if svc_model.predict(comp_train.iloc[[i,]])==0 and train_ans.iloc[i]==1:\n",
    "        FN = FN + 1\n",
    "        \n",
    "print(\"Model\", \"True Pos - \",TP, \"False Pos -\",FP,\"True Neg - \", TN, \"False neg - \",FN)\n",
    "\n",
    "model_accuracy = (TP+TN)/(len(train_ans))\n",
    "model_precision = TP/ (TP+FP)\n",
    "model_recall = TP/(TP+FN)\n",
    "model_f1 = 2*(model_precision * model_recall) / (model_precision + model_recall)\n",
    "\n",
    "print(\"Model's Accuracy:\", model_accuracy * 100, '%')\n",
    "print(\"Model´s Precision:\", model_precision *100,'%')\n",
    "print(\"Model´s Recall:\", model_recall *100,'%')\n",
    "print(\"Model´s F1:\", model_f1 *100,'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as we can see, the most important metric for us, Recall was pretty good, with 99% which will come down to 90% in new use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b> 2.5 Prediction </b>\n",
    "Now lets take our model for a test drive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your text:  fuck u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[Not Urgent] - Simple query, will be dealt with by the sytem.\n"
     ]
    }
   ],
   "source": [
    "def query_classifier(new_input):\n",
    "  new_input=[new_input]\n",
    "\n",
    "  new_input_vectorized = vec.fit_transform(new_input)\n",
    "  new_input_vectorized=pd.DataFrame(new_input_vectorized.toarray())\n",
    "  \n",
    "  compressing_new_input= train.append(new_input_vectorized, ignore_index=True)\n",
    "  pca_input_compressor= PCA(n_components=comp_cols, svd_solver='full')\n",
    "  \n",
    "  compressing_new_input= pd.DataFrame(pca_input_compressor.fit_transform(compressing_new_input))\n",
    "  \n",
    "  new_input_compressed = compressing_new_input.iloc[[(len(compressing_new_input.index)-1),]]\n",
    "\n",
    "  prediction=svc_model.predict(new_input_compressed)\n",
    "  \n",
    "  if prediction==0:\n",
    "    print(prediction)\n",
    "    print(\"[Not Urgent] - Simple query, will be dealt with by the sytem.\")\n",
    "  else:\n",
    "    print(prediction)\n",
    "    print(\"[Urgent] - Complex query, needs human intervention.\")\n",
    "    \n",
    "\n",
    "new_input= (input(\"Enter your text: \"))\n",
    "\n",
    "\n",
    "query_classifier(new_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "\n",
    "## 3. Conclusion\n",
    "\n",
    "So that's about it. It's amazing how we can apply Machine learning to simplest of things and make it more effiecient.\n",
    "<br> \n",
    "\n",
    "Links:\n",
    "\n",
    "* Portfolio : https://gofornaman.github.io\n",
    "* LinkedIn : https://www.linkedin.com/in/naman-doshi/\n",
    "\n",
    "----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
